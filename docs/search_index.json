[["index.html", "NYC Crime Chapter 1 Introduction", " NYC Crime Group 32: Abhiram Gaddam, Faizan Dogar, Devan Samant 2022-12-02 Chapter 1 Introduction "],["outlineworknotes.html", "Chapter 2 Outline/Work/Notes", " Chapter 2 Outline/Work/Notes Introduction - “Explain why you chose this topic, and the questions you are interested in studying. Provide context for readers who are not familiar with the topic.” Data copy proposal wording back into data section –Focus: Just around Upper Manhattan (if enough data) Profiling Describe any issues / problems with the data, either known or that you discover. NULL values - Binning for dates Potential date mismatch of when crime happened vs when crime was reported Recreate some basic statistics about the data we have using bar charts or whatever Google to see how others used dataset https://towardsdatascience.com/analysis-of-nyc-reported-crime-data-using-pandas-821753cd7e22 https://www.kaggle.com/datasets/adamschroeder/crimes-new-york-city https://jingjing-ge.medium.com/analysis-of-crime-data-in-new-york-city-in-2020-e6a65edf4429 https://www.kaggle.com/code/spoons/nyc-crime-complaints-guided-eda-with-shiny-app Data Cleaning need a metric count of crimes derived field of the distance from morningside park center to the row’s coordinate (ie. radius nearby –need another package) derived field about the severity or relcassify crime - (ex parking tickets). To reduce distinct number down to something managble. derive day of week from the datetime field date cleanups using data dictionary and maybe some assumptions so that we have a more accurate point in time (just use start) Results / Graph Ideas Univariate/Multivariate Categorical Ideas: crime frequency vs gender/age group/borough –maybe bar charts or mosaics Continuous Variable Ideas: (Interactive) changing radius from (morningside) park to see impact on crime rate density (frequency/area of radius). Take snapshots at like .25mi, .5mi, .75 etc as x-axis and plot density on y Time series (over months/days of week) - look at changes over time/seasonality (interactive) - control time lapse of heatmap of NYC or something Time (during the day) - Map: Ideas: compare NYU vs Columbia Compare walking vs subway (using premise) "],["tasks.html", "Chapter 3 Tasks", " Chapter 3 Tasks Get coordinates data for a specific location and use that calculate the distance from each complaint –Faizan We need to assign categories to crimes –Abhi Look into how best to use the time variables for various time series analyses General exploration of data (via online viz or R) / take notes on missing value cleanup/interesting findings –All "],["next-steps-note-2022-11-13.html", "Chapter 4 Next Steps Note 2022-11-13", " Chapter 4 Next Steps Note 2022-11-13 Agree on Data Prep Steps Derived Fields - a few for time series (Devan) - day night - was time estimated or not - crime category (Abhi) - distance from XYZ location - Columbia, NYU?, tbd (Faizan) - Aggregate Field for Premise (3-4 values, simple to use) - like street/park/inside/subway? - Combines inside/outside and premise and anythign else nee(incl. something for subway) - “Relevant Crime for EDAV” - victim is an individual and crime type is relevant or some aggregate of the two –Abhi to look at percentages and determine how to filter. May need to recategorize and/or use the victim sex field - (Other flags as needed) – Missing Value Analysis - Need to satisfy requirement for project - Describe any missing values in fields For date (Devan) - Look at difference between date reported and date of incident if anything interesting For crime type (Abhi) - There are 5 values with missing &quot;OFNS_DESC&quot;. Since they have valid PD_CD and PD_DESC, we can impute these values from other columns with the same PD_CD two values are for obscenity - 594 PD_CD. categorized as sex crimes one values for crime pos weap - 797 PD_CD. categorized as dangerous weapons one value for &quot;place false bomb&quot; - 648 PD_CD. No other examples of this crime. Ignore? one value for &quot;noise&quot; - 872 PD_CD. No other examples of this crime. Ignore? Placeholder for anything else Data Filtration Justification (missing and not relevant) Date - We only have crimes that took place (as defined by derived field above) in 1/1/2022 onward (this should remove 5%) (Devan) Crime Type - Use the derived field from above Location? - Tentative, only look within 3.2km of Columbia (per derived field above) Guiding Questions to keep in mind What is the safest route back home, - interactive component? Is cutting through the park bad? - what is a dangerous time to be out? Is there a difference by gender/race/age for safety? Analyses Demographics - 3+ (mosaic, ) –tbd to see what is interesting (All) Time - 3 graphs (line graph, ridge plot, bar chart/split?) Location - 2 graphs (map, crime density at different radiaii, routes to uptown?) -how to represent overlapping lat/long points differently? Color (Faizan) ——– Interactive - TBD, depends on complexity - Maybe user will enter address and then it will show a map that is shown around columbia and that location and basically plots heat map but allows user to add filters to make more specific and change the heatmap (ex change time or day or gender) "],["proposal.html", "Chapter 5 Proposal 5.1 Research topic 5.2 Data availability", " Chapter 5 Proposal 5.1 Research topic Have you ever gotten out of a class at 9:30pm and wondered if it was safe to walk home? Do you wonder if you should cut through a park or take the subway? Is it possible to quantify “safe”? Does your risk profile change after 10:30pm or if you are a certain gender? The motivation for this project spawned from these practical questions we had in relation to navigating NYC on and off campus. Many of our classes get out at night and we live nearby but wonder if there is a walking path home that exhibits the least risk. We want to answer these types of questions using data and visualizations. The focus of this project is to analyze NYPD crime and complaint data around Columbia during the school year. However, the data (described more in the next section) lends itself to investigate broader questions of equity by demographics and neighborhood across NYC. We also have flexibility in the time range to investigate and may look at longer trends. 5.2 Data availability NYC Open Data (NYC Office of Technology and Innovation (OTI)) in conjunction with New York City Police Department (NYPD) makes public safety data available for anyone online. In particular they publish Complaint Data which contains felony, misdemeanor, and violation crimes reported to the NYPD from 2006 till present. Year-to-Date (YTD): https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243 Historic: https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i 5.2.1 Content “Complaint data” is a mixed set of records because it contains crimes (ex. robbery, rape, assault), parking violations, complaints of harassment, reports of abandoned animals, and more. We will need to investigate, clean, and filter the data to answer our research questions. As the links above indicate, there are two sets of data containing distinct records. A year-to-date dataset from 1/1/2022 to 9/30/2022 and a historic dataset containing records from 1/1/2006 to 12/31/2021. We plan to start with the year-to-date data and potentially incorporate historic records as needed. The dataset contains mostly categorical variables and dates with each row indicating a crime/violation. As of the last update on October 19, 2022, the YTD Dataset contains 397K rows and 36 columns. A data dictionary is provided by NYC Open Data at the link above. Column names and description: S.No Column Name (Data Type): Description CMPLNT_NUM (text): Randomly generated persistent ID for each complaint ADDR_PCT_CD (text): The precinct in which the incident occurred BORO_NM (text): The name of the borough in which the incident occurred CMPLNT_FR_DT (DateTime): Exact date of occurrence for the reported event (or starting date of occurrence, if CMPLNT_TO_DT exists) CMPLNT_FR_TM (text): Exact time of occurrence for the reported event (or starting time of occurrence, if CMPLNT_TO_TM exists) CMPLNT_TO_DT (DateTime): Ending date of occurrence for the reported event, if exact time of occurrence is unknown CMPLNT_TO_TM (text): Ending time of occurrence for the reported event, if exact time of occurrence is unknown CRM_ATPT_CPTD_CD (text): Indicator of whether crime was successfully completed or attempted, but failed or was interrupted prematurely HADEVELOPT (text): Name of NYCHA housing development of occurrence, if applicable HOUSING_PSA (Number): Development Level CodeNumber JURISDICTION_CODE (Number): Jurisdiction responsible for incident. Either internal, like Police(0), Transit(1), and Housing(2); or external(3), like Correction, Port Authority, etc. JURIS_DESC (text): Description of the jurisdiction code KY_CD (Number): Three digit offense classification code LAW_CAT_CD (text): Level of offense: felony, misdemeanor, violation LOC_OF_OCCUR_DESC (text): Specific location of occurrence in or around the premises; inside, opposite of, front of, rear of OFNS_DESC (text): Description of offense corresponding with key code PARKS_NM (text): Name of NYC park, playground or greenspace of occurrence, if applicable (state parks are not included) PATROL_BORO (text): The name of the patrol borough in which the incident occurred PD_CD (Number): Three digit internal classification code (more granular than Key Code) PD_DESC (text): Description of internal classification corresponding with PD code (more granular than Offense Description) PREM_TYP_DESC (text): Specific description of premises; grocery store, residence, street, etc. RPT_DT (DateTime): Date event was reported to police STATION_NAME (text): Transit station name SUSP_AGE_GROUP (text): Suspect’s Age Group SUSP_RACE (text): Suspect’s Race Description SUSP_SEX (text): Suspect’s Sex Description TRANSIT_DISTRICT (Number): Transit district in which the offense occurred VIC_AGE_GROUP (text): Victim’s Age Group VIC_RACE (text): Victim’s Race Description VIC_SEX (text): Victim’s Sex Description X_COORD_CD (Number): X-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104) Y_COORD_CD (Number): Y-coordinate for New York State Plane Coordinate System, Long Island Zone, NAD 83, units feet (FIPS 3104) Latitude (Number): Midblock Latitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326) Longitude (Number): Midblock Longitude coordinate for Global Coordinate System, WGS 1984, decimal degrees (EPSG 4326) LatLon (Location) New Georeferenced Column (Point) 5.2.2 Who Collects The Data The data was collected and published by the NY Police Department (NYPD). 5.2.3 Format and Importation OTI provides the data in 4 formats: 1) online table, 2) visualization, 3) CSV, and 4) API. The first two have limited functionality and customization so we will not use those versions. The API requires an account and authentication tokens. Given that the CSV for YTD data is not too large (140MB), it seems the easiest to work with. CSV is a format we are most familiar with and one that R handles well. Is there a difference between CSV and API? Yes. Not in number of observations but in the columns. With the CSV, we get a total of 36 columns (listed above) but with the API we get a total of 41 columns. Following are the columns that are present in the CSV data but not in the API data: New Georeferenced Column. Following are the columns that are present in the API data but not in the CSV data: :@computed_region_92fq_4b7q :@computed_region_yeji_bk3q :@computed_region_efsh_h5xi geocoded_column :@computed_region_sbqj_enih :@computed_region_f5dn_yrer 5.2.4 Updates This dataset was first made public on 11/1/2018. It is updated quarterly. It appears that the metadata is updated more frequently but it is not clear what changes are incorporated as there could be several updates made in Oct 2022 but the data will only contain records up to the prior month end of Sept 2022. 5.2.5 Expected Challenges The data does not have many continuous variables. We will have to derive one based on counts and may need to supplement with other data to obtain others (ex. average cost/insurance per type of crime). There are longitude and latitude fields which we would like to utilize but have not identified an R package to process and visualize. "],["data.html", "Chapter 6 Data 6.1 Sources 6.2 Cleaning / transformation 6.3 Missing value analysis", " Chapter 6 Data library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.1 ## ✔ readr 2.1.2 ✔ forcats 0.5.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(ggplot2) library(dplyr) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(ggridges) library(geosphere) ## Warning: package &#39;geosphere&#39; was built under R version 4.2.2 library(redav) #remotes::install_github(&quot;jtr13/redav&quot;) #Unused Libraries: #library(readr) 6.1 Sources TODO - WRITEUP/repeate proposal 6.1.1 Data Loading #Group32 - This file has been added to gitignore so it will not be uploaded. So we are on the same page and can run the same code, add the csv to your local project folder in a new subfolder &quot;data&quot;. #df_raw &lt;- read_csv(&#39;./data/NYPD_Complaint_Data_Current__Year_To_Date_.csv&#39;) df_raw &lt;- read_csv(&#39;./data/NYPD_Complaint_Data_Current__Year_To_Date_.csv&#39; , col_types= cols( CMPLNT_NUM = col_character() #was loading as number so numbers with letters were showing as null ) ) #View(df_raw) #head(df_raw) 6.2 Cleaning / transformation –TODO 1) Re-categorize and clean Offense Type 2) Derive Date/Time fields 3) 6.2.0.1 Offense Type 6.2.0.2 Imputing null values For crime type (Abhi) - There are 5 values with missing “OFNS_DESC”. Since they have valid PD_CD and PD_DESC, we can impute these values from other columns with the same PD_CD two values are for obscenity - 594 PD_CD. categorized as sex crimes one values for crime pos weap - 797 PD_CD. categorized as dangerous weapons one value for “place false bomb” - 648 PD_CD. No other examples of this crime. Ignore? one value for “noise” - 872 PD_CD. No other examples of this crime. Ignore? df &lt;- df_raw df$OFNS_DESC[df$CMPLNT_NUM %in% c(&quot;248613125&quot;, &quot;248290778&quot;)] &lt;- &quot;SEX CRIMES&quot; df$OFNS_DESC[df$CMPLNT_NUM %in% (&quot;246605653&quot;)] &lt;- &quot;DANGEROUS WEAPONS&quot; 6.2.1 Creating a new column to bucket crimes df &lt;- df %&gt;% mutate(CRIME_CAT = case_when( OFNS_DESC %in% c(&quot;RAPE&quot;, &quot;SEX CRIMES&quot;, &quot;HARRASSMENT 2&quot;, &quot;FELONY SEX CRIMES&quot;, &quot;PROSTITUTION &amp; RELATED OFFENSES&quot;) ~ &quot;SEX CRIMES&quot;, OFNS_DESC %in% c(&quot;DANGEROUS DRUGS&quot;,&quot;CANNABIS RELATED OFFENSES&quot;,&quot;INTOXICATED &amp; IMPAIRED DRIVING&quot;,&quot;ALCOHOLIC BEVERAGE CONTROL LAW&quot;,&quot;INTOXICATED/IMPAIRED DRIVING&quot;) ~ &quot;DRUG AND ALCOHOL RELATED&quot;, OFNS_DESC %in% c(&quot;ROBBERY&quot;,&quot;GRAND LARCENY&quot;,&quot;THEFT-FRAUD&quot;,&quot;PETIT LARCENY&quot;,&quot;BURGLARY&quot;,&quot;GRAND LARCENY OF MOTOR VEHICLE&quot;,&quot;POSSESSION OF STOLEN PROPERTY&quot;,&quot;THEFT OF SERVICES&quot;,&quot;BURGLAR&#39;S TOOLS&quot;,&quot;PETIT LARCENY OF MOTOR VEHICLE&quot;,&quot;OTHER OFFENSES RELATED TO THEF&quot;) ~ &quot;THEFT OR BURGLARY&quot;, OFNS_DESC %in% c(&quot;DANGEROUS WEAPONS&quot;,&quot;MURDER &amp; NON-NEGL. MANSLAUGHTER&quot;,&quot;KIDNAPPING &amp; RELATED OFFENSES&quot;,&quot;HOMICIDE-NEGLIGENT,UNCLASSIFIE&quot;,&quot;HOMICIDE-NEGLIGENT-VEHICLE&quot;,&quot;KIDNAPPING&quot;,&quot;FELONY ASSAULT&quot;,&quot;ARSON&quot;,&quot;ASSAULT 3 &amp; RELATED OFFENSES&quot;,&quot;UNLAWFUL POSS. WEAP. ON SCHOOL&quot;,&quot;MURDER &amp; NON-NEGL. MANSLAUGHTER&quot;) ~ &quot;MAJOR VIOLENT CRIMES&quot;, OFNS_DESC %in% c(&quot;CRIMINAL MISCHIEF &amp; RELATED OF&quot;,&quot;UNAUTHORIZED USE OF A VEHICLE&quot;,&quot;FRAUDS&quot;,&quot;OFFENSES AGAINST PUBLIC SAFETY&quot;,&quot;DISORDERLY CONDUCT&quot;,&quot;JOSTLING&quot;,&quot;DISRUPTION OF A RELIGIOUS SERV&quot;,&quot;ESCAPE 3&quot;,&quot;OFF. AGNST PUB ORD SENSBLTY &amp;&quot;,&quot;CRIMINAL TRESPASS&quot;,&quot;VEHICLE AND TRAFFIC LAWS&quot;,&quot;GAMBLING&quot;,&quot;OFFENSES AGAINST THE PERSON&quot;,&quot;OFFENSES INVOLVING FRAUD&quot;,&quot;FRAUDULENT ACCOSTING&quot;,&quot;ANTICIPATORY OFFENSES&quot;,&quot;LOITERING/GAMBLING (CARDS, DIC&quot;) ~ &quot;FRAUD/GAMBLING AND MISC&quot;, OFNS_DESC %in% c(&quot;NYS LAWS-UNCLASSIFIED FELONY&quot;,&quot;MISCELLANEOUS PENAL LAW&quot;,&quot;FORGERY&quot;,&quot;OFFENSES AGAINST PUBLIC ADMINI&quot;,&quot;CHILD ABANDONMENT/NON SUPPORT&quot;,&quot;NYS LAWS-UNCLASSIFIED VIOLATION&quot;,&quot;OTHER STATE LAWS&quot;,&quot;OTHER STATE LAWS (NON PENAL LAW)&quot;,&quot;NEW YORK CITY HEALTH CODE&quot;,&quot;ADMINISTRATIVE CODE&quot;,&quot;OTHER STATE LAWS (NON PENAL LA&quot;,&quot;AGRICULTURE &amp; MRKTS LAW-UNCLASSIFIED&quot;,&quot;ENDAN WELFARE INCOMP&quot;,&quot;OFFENSES RELATED TO CHILDREN&quot;) ~&quot;OTHER&quot;)) df$CRIME_CAT[df$CMPLNT_NUM %in% c(&quot;243170965&quot;, &quot;245874611&quot;)] &lt;- &quot;OTHER&quot; #No Nulls #View(df[is.na(df$CRIME_CAT),]) 6.2.2 Date/Time 6.2.2.1 Cleaning null values/ranges Per the data dictionary, there is both a “from_date” and a “to_date” when the exact time is unknown. There is also a “report date” for when the crime was reported. Using these fields in conjunction, we can derive a new clean field that is the assumed date of the incident. Assumptions: When there is a range, we will use the “from” date only because is populated well and will on average approximate the frequency of crime over time; when from_date is null, we will use the report_date (does not occur often, see Missing Data Analysis below). df &lt;- df %&gt;% mutate( #use from date and report date if null. If to_date then just use from date and we can argue it averages out since new reports will start as other end Incident_Date_raw = case_when (is.null(CMPLNT_FR_DT) ~ RPT_DT ,CMPLNT_FR_DT == &quot;(null)&quot; ~ RPT_DT ,TRUE ~ CMPLNT_FR_DT ) #flag if estimated (ie from date is null or to date is populated) ,Incident_Date_Estimated_Flag = case_when ( is.null(CMPLNT_FR_DT) ~ &#39;Y&#39; ,CMPLNT_FR_DT == &quot;(null)&quot; ~ &#39;Y&#39; ,!is.null(CMPLNT_TO_DT) ~ &#39;Y&#39; ,CMPLNT_TO_DT != &quot;(null)&quot; ~ &#39;Y&#39; ,TRUE ~ &#39;N&#39; ) ) #Convert to times df &lt;- df %&gt;% mutate( #creating date and time together for lubridate Incident_Date = as.Date(Incident_Date_raw, format = &#39;%m/%d/%Y&#39;) ,Incident_Datetime = as.POSIXct(paste(Incident_Date_raw,CMPLNT_FR_TM), format = &#39;%m/%d/%Y %H:%M:%S&#39;) ) %&gt;% mutate( Incident_HourTime = hour(Incident_Datetime) + minute(Incident_Datetime)/60 ,Incident_Month = month(Incident_Date) ,Incident_DayOfWeek = wday(Incident_Date, label = TRUE, abbr = TRUE) ) 6.2.3 GeoLocation Fields #add column for Columbia location CU_Latitude = 40.807384 CU_Longitude = -73.963036 #df_test = df[1:10,] #df_test$dist_to_CU &lt;- apply(df_test, 1, function(x)distm(c(x[which( colnames(df)==&quot;Longitude&quot;)],x[which(colnames(df)==&quot;Latitude&quot;)]),c(x[which( colnames(df)==&quot;CU_Longitude&quot;)],x[which( colnames(df)==&quot;CU_Latitude&quot;)]),fun = distGeo)) df$dist_to_CU &lt;- apply(df, 1, function(x)distm( c(x[which( colnames(df)==&quot;Longitude&quot;)],x[which(colnames(df)==&quot;Latitude&quot;)]) ,c(CU_Longitude,CU_Latitude) ,fun = distGeo) ) –#TODO can we speed this up? Takes about 5 mins to run 6.2.4 Other Derivations Here we will add additional fields for more classification –#TODO add more description df$LOC_OF_OCCUR_DESC[df$LOC_OF_OCCUR_DESC==&quot;(null)&quot;]&lt;-NA df &lt;- df %&gt;% mutate( #get a flag for outside vs inside Inside_Outside = case_when ( LOC_OF_OCCUR_DESC %in% c(&quot;FRONT OF&quot; , &quot;OPPOSITE OF&quot; , &quot;REAR OF&quot;) ~ &quot;OUTSIDE&quot; ,LOC_OF_OCCUR_DESC %in% c(&quot;INSIDE&quot;) ~ &quot;INSIDE&quot; #,LOC_OF_OCCUR_DESC == &quot;(null)&quot; ~ NULL #TODO -cant figure this out error ,TRUE ~ LOC_OF_OCCUR_DESC ) #if victim was a person (not a business/govt) ,VIC_Individual_Flag = case_when ( VIC_SEX %in% c(&quot;M&quot;,&quot;F&quot;,&quot;L&quot;) ~ &#39;Y&#39; ,TRUE ~ &#39;N&#39; ) ) %&gt;% mutate( Complaint_Count = 1 #maybe want to add like a intensity value or something? #TODO, make this field a little better/check values? ,Premise_Derived = case_when ( Inside_Outside == &#39;INSIDE&#39; ~ &#39;INSIDE&#39; ,PREM_TYP_DESC ==&quot;RESIDENCE - APT. HOUSE&quot; &amp; (Inside_Outside == &quot;(null)&quot; | is.null(Inside_Outside)) ~ &#39;INSIDE&#39; ,!is.null(PARKS_NM) &amp; PARKS_NM != &quot;(null)&quot; ~ &#39;PARK&#39; ,PREM_TYP_DESC %in% c(&quot;TRANSIT - NYC SUBWAY&quot;,&quot;BUS (NYC TRANSIT)&quot;,&quot;TRANSIT FACILITY (OTHER)&quot;) ~ &#39;SUBWAY&#39; ,TRUE ~ &#39;STREET&#39; ) ) 6.2.5 Filter Table for Relevance –#TODO add more description Date - We only have crimes that took place (as defined by derived field above) in 1/1/2022 onward (this should remove 5%) (Devan) Crime Type - Use the derived field from above Location? - Tentative, only look within 3.2km of Columbia (per derived field above) df_filter &lt;- df %&gt;% filter( Incident_Date &gt;= as.Date(&#39;2022/01/01&#39;) ) %&gt;% filter ( !CRIME_CAT %in% c(&quot;OTHER&quot;) ) #TODO- distance filter? #View(df_filter) #unique(df_filter$CRIME_CAT) This improves the results as we will show in the chapter. There are not many records that are excluded (396978 - 364298) 6.2.6 Select and Rename Columns in a Usuable Table –#TODO add more description #Not required df_key_fields &lt;- df_filter %&gt;% select( #Basic Info CMPLNT_NUM #,CRM_ATPT_CPTD_CD #,Complaint_Count #derived #Date Info ,Incident_Date_raw #derived #,Incident_Date_Estimated_Flag #derived #,Incident_Date #derived #,Incident_Datetime #derived #,Incident_HourTime #derived #,Incident_Month #derived #,Incident_DayOfWeek #derived ,CMPLNT_FR_DT ,CMPLNT_FR_TM #,CMPLNT_TO_DT #,CMPLNT_TO_TM ,RPT_DT #Location Info #,Inside_Outside #derived #missing a lot (because derived on field below) #,CU_Latitude #derived #,CU_Longitude #derived ,dist_to_CU #derived ,Premise_Derived #derived #,ADDR_PCT_CD ,BORO_NM #,HADEVELOPT #,HOUSING_PSA #,JURISDICTION_CODE ,JURIS_DESC #,LOC_OF_OCCUR_DESC #missing a lot (because of privacy) #,PARKS_NM #,PATROL_BORO #,PD_CD #,PD_DESC #,PREM_TYP_DESC #,STATION_NAME #,TRANSIT_DISTRICT #,X_COORD_CD #,Y_COORD_CD #,Latitude #,Longitude ,Lat_Lon #,`New Georeferenced Column` #Crime Info ,CRIME_CAT #derived #,VIC_Individual_Flag #derived #,KY_CD ,LAW_CAT_CD ,OFNS_DESC ,SUSP_AGE_GROUP ,SUSP_RACE ,SUSP_SEX ,VIC_AGE_GROUP ,VIC_RACE ,VIC_SEX ) 6.3 Missing value analysis First we can look at the raw data to see what things look like. plot_missing(df, percent = FALSE) #View(df[!is.na(df$TRANSIT_DISTRICT),]) plot_missing( df[ , !colnames(df) %in% c(&quot;TRANSIT_DISTRICT&quot;,&quot;HOUSING_PSA&quot;) ] , percent = FALSE) These charts are hard to read given the number of columns but it shows that most data is actually populated very well. There are two problem fields causing all of nulls but we can regraph this without those and see that complete cases are at the top. However, this is still not accurate because there are string values in the data that say “(null)” which would appear as populated. In any case, we do not need to clean and evaluate all columns, so let us work off of the new, filtered dataset (see below). Side Note: We initially noticed the Complaint_Num was null often but this was due to containing alphanumeric characters but readr loaded it as a number only plot_missing(df_key_fields, percent = FALSE) #View(df_key_fields[is.na(df_key_fields$CMPLNT_NUM),]) The filtered data (relevant columns and rows only) is populated very well and this dataset accounts for improperly coded values where “(null)” will appear as NULL properly. We see there are a few blanks for lat/long and thus the related derived field, but otherwise we have a good dataframe to use. "],["results.html", "Chapter 7 Results 7.1 Planning Notes 7.2 Crime category and Demographic analysis 7.3 Time Series", " Chapter 7 Results library(scales) #library(vcdExtra) library(ggplot2) library(forcats) library(dplyr) library(Lock5withR) library(tidyr) 7.1 Planning Notes –To delete #What Graphs Do We Want? #Data Prep Graphs #1) Missing data patterns by row (using redav library or mi library) --heatmap #Demographic Related Chart #1) Bar Chart - CRIME_CAT by VIC Gender and/or SUSPECT Gender #2) Mosaic Plot - TBD (CRIME CAT, VIC Gender, and Premise, +) #3) Count by Premise (or use as a cut) #--see ideas below #Time Series Charts #1) Line Chart - Overall 2022 Trend by Count #2) Bar Chart - CRIME CAT by Day of Week #3) Density Plot - Count by Time of Day (maybe with facets) #4) (TBD more CRIME CAT by Time or Premise by Time of Day/Park) #5) Look at box plot by time of day? #Maps &amp; Distance Info #1) Counts By Borough (bar chart) (consider faceting by another dimension that looks good) #2) Map of count in Columbia Area #3) Line Graph of Density At Diff Points (x is distance from CU and y is total counts) #4) Heat Map/Choropleth - Count by Precinct Code (may require addl data? --look into if feasible) #Other Potential #x) Parallel Coordinates Plot - not enough continuous vars #x) Stacked Bar Chart? #x) Scatter Plot (of Distance from CU vs Time of Day?) #x) Cleveland Dot Plot - TBD 7.2 Crime category and Demographic analysis agg_tbl &lt;- df_key_fields%&gt;% group_by(CRIME_CAT) %&gt;% summarise(total_count=n(), .groups = &#39;drop&#39;) df_counts &lt;- agg_tbl %&gt;% as.data.frame() ggplot(df_counts) + geom_bar(aes(y=CRIME_CAT, x=total_count), stat=&quot;identity&quot;,fill = &quot;cornflowerblue&quot;)+ ggtitle(&quot;Number of crimes per category &quot;) + xlab(&quot;Count&quot;) + ylab(&quot;Category&quot;) We start our analysis of crime types by observing that theft or burglary related crimes are the most common by far (more than 2x the next highest category). This category is followed by sex crimes, violent crimes, and fraud/gambling related crimes all of which are relatively close in number. The lowest crime category by far is drug and alcohol related crimes. We can investigate the data to see the top 10 kinds of crimes before we bucket them into categories. df_key_fields %&gt;% group_by(OFNS_DESC) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% slice(1:10) %&gt;% ggplot(aes(y=fct_reorder(OFNS_DESC,freq,.desc = FALSE),x=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + ggtitle(&quot;Top 10 Most Common Types of Crime&quot;) + xlab(&quot;Counts&quot;) + ylab(&quot;Type of Crime&quot;) —Maybe we make this chart a clevland dot plot with all original crimes categories and colored by crime_cat? Maybe facet, idk. –COLOR NOT WORKING df_key_fields$FCT_CRIME_CAT &lt;- as.factor(df_key_fields$CRIME_CAT) df_key_fields %&gt;% group_by(OFNS_DESC) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% slice(1:10) %&gt;% ggplot(aes(x = freq, y = fct_reorder(OFNS_DESC, freq))) + geom_segment(aes(yend = OFNS_DESC), xend = 0, colour = &quot;grey50&quot;) + geom_point(color = &quot;blue&quot;, size = 3, aes(colour = FCT_CRIME_CAT)) + ggtitle(&quot;Top 10 Most Common Types of Crime&quot;) + xlab(&quot;Counts&quot;) + ylab(&quot;Type of Crime&quot;) Here, we can see the crime incident that has happened the most frequently is “Petit Larceny”, a form of larceny in which the value of the property taken is generally less than $50. Further, five of the top 10 crimes are theft or burglary related, which explains why the most common crime category reported is theft. We can start our demographic analysis by digging further into the race, age, and gender of both suspects and victims. df_key_fields %&gt;% group_by(SUSP_RACE) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% slice(1:7) %&gt;% ggplot(aes(x=fct_reorder(SUSP_RACE,freq,.desc = TRUE),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + scale_x_discrete(guide = guide_axis(n.dodge=3))+ ggtitle(&quot;Suspect Race vs Total Count&quot;) + xlab(&quot;Race&quot;) + ylab(&quot;Count&quot;) df_key_fields %&gt;% group_by(VIC_RACE) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% slice(1:6) %&gt;% ggplot(aes(x=fct_reorder(VIC_RACE,freq,.desc = TRUE),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + scale_x_discrete(guide = guide_axis(n.dodge=3))+ ggtitle(&quot;Victim Race vs Total Count&quot;) + xlab(&quot;Race&quot;) + ylab(&quot;Count&quot;) While there is a lot of null and unknown data, presumably for the sake of anonymity, we notice that there are trends between the race of the suspect and victim. Lets see if we observe something similar for the sex of a victim and suspect df_key_fields %&gt;% group_by(SUSP_SEX) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% #slice(1:6) %&gt;% ggplot(aes(x=fct_reorder(SUSP_SEX,freq,.desc = TRUE),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + #scale_x_discrete(guide = guide_axis(n.dodge=3))+ ggtitle(&quot;Suspect Sex vs Total Count&quot;) + xlab(&quot;Sex&quot;) + ylab(&quot;Count&quot;) df_key_fields %&gt;% group_by(VIC_SEX) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% #slice(1:6) %&gt;% ggplot(aes(x=fct_reorder(VIC_SEX,freq,.desc = TRUE),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + #scale_x_discrete(guide = guide_axis(n.dodge=3))+ ggtitle(&quot;Victim Sex vs Total Count&quot;) + xlab(&quot;Sex&quot;) + ylab(&quot;Count&quot;) Clearly most of the crimes committed are by men, and most of the victims are female. –ATTEMPT AT MOSAIC PLOT counts2 &lt;- df_key_fields %&gt;% group_by(VIC_RACE, SUSP_RACE) %&gt;% summarize(Freq = n()) vcd::mosaic(VIC_RACE ~ SUSP_RACE, counts2, direction = c(&quot;v&quot;, &quot;h&quot;),) 7.3 Time Series To begin the analysis on time, first we would like to justify why we filtered the data for only crimes that took place in 2022. ts_year_all &lt;- df %&gt;% #filter(year(Incident_Date) &gt;= 2022) %&gt;% group_by(year(Incident_Date)) %&gt;% summarize(Complaint_Count = n() ) %&gt;% rename( Incident_Year = `year(Incident_Date)`) ggplot(ts_year_all, aes(x=Incident_Year, y=Complaint_Count )) + geom_line() + scale_y_continuous(label=comma) + scale_x_continuous(limits= c(2000,2023) ) + labs( title = &quot;Date of Incident (Reported in 2022)&quot;, x = &quot;Incident Year (raw data)&quot;, y = &quot;Number of Reports&quot;, ) From this we see that there is a large drop off in historic reports. This make sense as it is more likely that someone would report a crime in the same year that it occurs. Although NYPD allows people to report crimes that occurred in 2020, there will be much fewer of them reported in 2022. If we wanted to use data prior to 2022 we should include the old crime reports for prior years. Also there are some quality issues with historic data as we see very old crimes (year 1500) which indicate some human error or a record-keeping issue. So focusing on incidents in 2022, we can look at the overall trend during the year. ggplot(df_filter, aes(x=Incident_Month)) + geom_line(aes(fill=..count..),stat=&quot;bin&quot;,binwidth=1) + scale_x_continuous(limits = c(1,9), n.breaks=12) + scale_y_continuous(limits = c(0,50000), label=comma) + labs( title = &quot;2022 Crimes Per Month (Q1-Q3)&quot;, x = &quot;Month (as a number)&quot;, y = &quot;Total Reports&quot;, ) #TODO make graph prettier We can see there are more crimes reported in the summer months, presumably it is warmer. Let’s facet this: ggplot(df_filter, aes(x=Incident_Month, color= fct_infreq(CRIME_CAT) )) + geom_line(aes(fill=..count..),stat=&quot;bin&quot;,binwidth=1) + scale_x_continuous(limits = c(1,9), n.breaks=12) + scale_y_continuous(limits = c(0,20000), label=comma) + #facet_grid((CRIME_CAT) ~ .) + labs( title = &quot;2022 Crimes Per Month (Q1-Q3)&quot;, x = &quot;Month (as a number)&quot;, y = &quot;Total Reports&quot;, color = &quot;Crime Category&quot; ) Maybe, the trend is dominated by theft crimes but it does seem like there is a hump over summer. Uniquely there is a dip for drug crimes. Let’s now look at some other time related charts #ggplot(df_filter, aes(x = Incident_DayOfWeek, fill=fct_infreq(CRIME_CAT))) + # geom_bar(stat=&#39;count&#39;, position=&#39;dodge&#39;) ggplot(df_filter, aes(y=CRIME_CAT , fill=fct_rev(Incident_DayOfWeek)) ) + geom_bar(stat=&#39;count&#39;, position=&#39;dodge&#39;) + scale_x_continuous(label=comma) + scale_fill_discrete(breaks=c(&#39;Sun&#39;,&#39;Mon&#39;,&#39;Tue&#39;,&#39;Wed&#39;,&#39;Thu&#39;,&#39;Fri&#39;,&#39;Sat&#39;)) + labs( title = &quot;2022 Crimes By Day of Week (Q1-Q3)&quot;, x = &quot;Total Reports&quot;, y = &quot;&quot;, fill = &quot;Day&quot; ) We see some interesting trends here - Theft is lower on weekends, gambling up on weekends, sex crimes high on Wednesdays surprisingly. Let’s also look at the time of the day: ggplot(df_filter, aes(x = Incident_HourTime, y=fct_rev(Incident_DayOfWeek) )) + geom_density_ridges() + scale_x_continuous(limits = c(0,24), breaks = seq(0, 24, by = 1)) + labs( title = &quot;Hourly Breakdown (Total Q1-Q3 2022)&quot;, x = &quot;Time of Day (24 Clock)&quot;, y = &quot;Day of Week&quot; ) #+ theme_classic(18) #TODO change theme to look better? #not quite sure why hour 24 does not equal hour 0... The raw data is rounded to the nearest minute but there is likely binning happening with time reported on the nearest hour. There also appears to be a peak at 12:00 which is likely a data quality issue in that reports may default to that time when not specified exactly. Otherwise this graph shows that crimes seems to peak at night around 6pm. But is this related to individual crimes and in/around parks? ggplot(df_filter, aes(x = Incident_HourTime, y=Premise_Derived )) + geom_density_ridges() + scale_x_continuous(limits = c(0,24), breaks = seq(0, 24, by = 1)) + facet_grid((VIC_Individual_Flag) ~ .) + labs( title = &quot;Crimes by Premise and Time&quot;, subtitle = &quot;Y = Indivuals, N = Entities/Businesses/NY State&quot;, x = &quot;Time of Day (24 Clock)&quot;, y = &quot;Premise Category&quot; ) #TODO Show counts for each of these groups since not representative (ex what is a crime against and entity in a park)? Refer back to moaisic plot From prior charts, we know that the number of crimes is skewed toward those occurring in “Inside”. This does not represent the magnitude but we can see that for individuals, parks are more ‘dangerous’ at night - more so than other locations. However, it is somewhat comforting to know that this starts to drop off quickly after about 7-8pm. #--Let&#39;s specifically look at crime around Columbia for Individuals #ts_filter &lt;- df_filter %&gt;% filter(VIC_Individual_Flag == &#39;Y&#39;) %&gt;% # filter(dist_to_CU &lt;= 2000) %&gt;% #only 10k rows # filter(Premise_Derived == &quot;PARK&quot;) #only 73 rows, not helpful #--Box plot by time of day? TBD "],["location-analysis.html", "Chapter 8 Location Analysis", " Chapter 8 Location Analysis "],["interactive-component.html", "Chapter 9 Interactive component 9.1 Test", " Chapter 9 Interactive component Test 123 9.1 Test (100, 150) "],["conclusion.html", "Chapter 10 Conclusion", " Chapter 10 Conclusion "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
