# Results

```{r setup_results, include=FALSE}
knitr::opts_chunk$set(echo= TRUE, warning = FALSE, message = FALSE)
```


## Crime category and Demographic analysis

We start our analysis of crime types by investigating which crime categories occur in what frequencies. We bucketed the numerous crimes that are listed into logical categories.

```{r}
agg_tbl <- df_key_fields%>% group_by(CRIME_CAT) %>% 
  summarise(total_count=n(),
            .groups = 'drop')
df_counts <- agg_tbl %>% as.data.frame()

ggplot(df_counts) + geom_bar(aes(y=CRIME_CAT, x=total_count), stat="identity",fill = "cornflowerblue")+
  ggtitle("Number of crimes per category ") +
  xlab("Count") +
  ylab("Category")
```
We observe that theft or burglary related crimes are the most common by far (more than 2x the next highest category). This category is followed by sex crimes, violent crimes, and fraud/gambling related crimes all of which are relatively close in number. The lowest  category by far is drug and alcohol related crimes, perhaps because the policing of these crimes has been relaxed over the last few years.


We can further investigate the data to see the top 15 kinds of crimes and what categories they belong to.
```{r}
df_key_fields$FCT_CRIME_CAT <- as.factor(df_key_fields$CRIME_CAT)

df_key_fields %>%
  group_by(OFNS_DESC,FCT_CRIME_CAT) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  filter(freq>2750) %>%
  ggplot(aes(x = freq, y = fct_reorder(OFNS_DESC, freq), color = FCT_CRIME_CAT)) +
  geom_segment(aes(yend = OFNS_DESC), xend = 0, colour = "grey50") +
  geom_point(size = 3, aes(color = FCT_CRIME_CAT)) +
  ggtitle("Top 10 Most Common Types of Crime") +
  xlab("Counts") +
  ylab("Type of Crime")
```

Here, we can see the crime incident that has happened the most frequently is “Petit Larceny”, a form of larceny in which the value of the property taken is generally less than $50. 

As expected, 5 of the top 10 crimes are theft or burglary related, which explains why the most common crime category reported is theft. Also, we only see one incident type corresponding to drug and alcohol related crimes.


We can start our demographic analysis by digging further into the race, age, and gender of both suspects and victims. 
Lets begin by diving into trends between the race of the suspects and victims.
```{r}
df_key_fields %>%
  group_by(SUSP_RACE) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  slice(1:7) %>%
  ggplot(aes(x=fct_reorder(SUSP_RACE,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Suspect Race vs Total Count") +
  xlab("Race") +
  ylab("Count")
```

```{r}
df_key_fields %>%
  group_by(VIC_RACE) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  slice(1:6) %>%
  ggplot(aes(x=fct_reorder(VIC_RACE,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Victim Race vs Total Count") +
  xlab("Race") +
  ylab("Count")
```
While there is a lot of null and unknown data, we notice that there are clear patterns between the race of the suspect and victim. Visualizing this using a heatmap convinces us of this.  

```{r}
ggplot(df_key_fields, aes(VIC_RACE, SUSP_RACE)) + 
  geom_bin2d()+
  scale_fill_viridis_c()+
  scale_x_discrete(guide = guide_axis(n.dodge=3)) +
  xlab("Suspect Race") +
  ylab("Victim Race") +
  ggtitle("Victim Race vs Suspect Race")

```

We see from the bar charts that most of the victims are black and also that most of the suspects are black. Logically, the intersection of these two fields is also the highest. 


Next, lets do a gender focused analysis.
```{r}
df_key_fields %>%
  group_by(SUSP_SEX) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  #slice(1:6) %>%
  ggplot(aes(x=fct_reorder(SUSP_SEX,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  #scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Suspect Sex vs Total Count") +
  xlab("Sex") +
  ylab("Count")
```

```{r}
df_key_fields %>%
  group_by(VIC_SEX) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  #slice(1:6) %>%
  ggplot(aes(x=fct_reorder(VIC_SEX,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  #scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Victim Sex vs Total Count") +
  xlab("Sex") +
  ylab("Count")
```
Most of the victims are female, followed closely by males. However, there is a large discrepancy in the counts of suspect genders. Males are by far the highest category, more than 4x the count for females.


```{r}
ggplot(df_key_fields, aes(SUSP_SEX,VIC_SEX)) + 
  geom_bin2d()+
  scale_x_discrete(guide = guide_axis(n.dodge=3))

```


--ATTEMPT AT MOSAIC PLOT 
```{r}
counts2 <- df_key_fields %>%
  group_by(VIC_RACE, SUSP_RACE) %>%
  summarize(Freq = n())
vcd::mosaic(VIC_RACE ~ SUSP_RACE, counts2, direction = c("v", "h"),)
```
--perhaps we can rename some values as a new field in the data.Rmd so that this shows a little cleaner? 

--try mixing and matching more fields in different moasics to see if anything pops? Open to other ideas but pretty sure we need a graph with 3+ categorical vars given this dataset.  Try mosaic pair plots too.
```{r}
counts3 <- df_key_fields %>%
  group_by(VIC_RACE, SUSP_RACE, CRIME_CAT, BORO_NM, VIC_Individual_Flag) %>%
  summarize(Freq = n())
vcd::mosaic(VIC_Individual_Flag ~ BORO_NM + CRIME_CAT, counts3, direction = c("v","v","h"),)
vcd::mosaic(CRIME_CAT ~ BORO_NM + VIC_Individual_Flag, counts3, direction = c("v","v","h"),)
```

--add other charts about borough or jurisdiction? Age group? Might need to try a bunch but we'll only include the ones we think look interesting (ie. where there is a pattern or anomaly/skew or something we can tie to real life)
```{r}
df_key_fields %>%
  group_by(VIC_AGE_GROUP) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  slice(1:10) %>%
  ggplot(aes(x=fct_reorder(VIC_AGE_GROUP,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Victim Age vs Total Count") +
  xlab("Age") +
  ylab("Count")
```

```{r}
df_key_fields %>%
  group_by(SUSP_AGE_GROUP) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  slice(1:10) %>%
  ggplot(aes(x=fct_reorder(SUSP_AGE_GROUP,freq,.desc = TRUE),y=freq)) +
  geom_bar(stat = "identity",fill = "cornflowerblue") +
  scale_x_discrete(guide = guide_axis(n.dodge=3))+
  ggtitle("Suspect Age vs Total Count") +
  xlab("Age") +
  ylab("Count")
```

Heat map version:
--need to clean these columns? add garbage values to unknown
```{r}
ggplot(df_key_fields, aes(VIC_AGE_GROUP, SUSP_AGE_GROUP)) + 
  geom_bin2d()+
  scale_fill_viridis_c()
```


## Time Series
To begin the analysis on time, first we would like to justify why we filtered the data for only crimes that took place in 2022. 
```{r}
ts_year_all <- df %>% 
  #filter(year(Incident_Date) >= 2022) %>%
  group_by(year(Incident_Date))  %>%
  summarize(Complaint_Count = n() ) %>% rename( Incident_Year = `year(Incident_Date)`)

ggplot(ts_year_all, aes(x=Incident_Year, y=Complaint_Count )) + geom_line() +
  scale_y_continuous(label=comma) +
  scale_x_continuous(limits= c(2000,2023) ) +
  labs(
    title = "Date of Incident (Reported in 2022)",
    x = "Incident Year (raw data)",
    y = "Number of Reports",
  )

```
From this we see that there is a large drop off in historic reports. This make sense as it is more likely that someone would report a crime in the same year that it occurs. Although NYPD allows people to report crimes that occurred in 2020, there will be much fewer of them reported in 2022. If we wanted to use data prior to 2022 we should include the old crime reports for prior years. Also there are some quality issues with historic data as we see very old crimes (year 1500) which indicate some human error or a record-keeping issue.  

So focusing on incidents in 2022, we can look at the overall trend during the year.
```{r}
ggplot(df_filter, aes(x=Incident_Month)) +
      geom_line(aes(fill=..count..),stat="bin",binwidth=1) +
      scale_x_continuous(limits = c(1,9), n.breaks=12) +
      scale_y_continuous(limits = c(0,50000), label=comma) +
      labs(
        title = "2022 Crimes Per Month (Q1-Q3)",
        x = "Month (as a number)",
        y = "Total Reports",
      )
#TODO make graph prettier
```
We can see there are more crimes reported in the summer months, presumably it is warmer. Let's facet this:

```{r}
ggplot(df_filter, aes(x=Incident_Month, color=
                        fct_infreq(CRIME_CAT)
                      )) +
      geom_line(aes(fill=..count..),stat="bin",binwidth=1) +
      scale_x_continuous(limits = c(1,9), n.breaks=12) +
      scale_y_continuous(limits = c(0,20000), label=comma) +
      #facet_grid((CRIME_CAT) ~ .) +
      labs(
        title = "2022 Crimes Per Month (Q1-Q3)",
        x = "Month (as a number)",
        y = "Total Reports",
        color = "Crime Category"
      ) 
```
Maybe, the trend is dominated by theft crimes but it does seem like there is a hump over summer. Uniquely there is a dip for drug crimes. 

Let's now look at some other time related charts
```{r}
#ggplot(df_filter, aes(x = Incident_DayOfWeek, fill=fct_infreq(CRIME_CAT))) + 
#  geom_bar(stat='count', position='dodge')

ggplot(df_filter, aes(y=CRIME_CAT , fill=fct_rev(Incident_DayOfWeek)) ) + 
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(label=comma) +
  scale_fill_discrete(breaks=c('Sun','Mon','Tue','Wed','Thu','Fri','Sat')) +
  labs(
      title = "2022 Crimes By Day of Week (Q1-Q3)",
      x = "Total Reports",
      y = "",
      fill = "Day"
      ) 
```
We see some interesting trends here - Theft is lower on weekends, gambling up on weekends, sex crimes high on Wednesdays surprisingly.

Let's also look at the time of the day:
```{r}
ggplot(df_filter, aes(x = Incident_HourTime, y=fct_rev(Incident_DayOfWeek) )) +
  geom_density_ridges() +
  scale_x_continuous(limits = c(0,24), breaks = seq(0, 24, by = 1)) +
  labs(
      title = "Hourly Breakdown (Total Q1-Q3 2022)",
      x = "Time of Day (24 Clock)",
      y = "Day of Week"
      ) #+ theme_classic(18)
#TODO change theme to look better?
#not quite sure why hour 24 does not equal hour 0...
```
The raw data is rounded to the nearest minute but there is likely binning happening with time  reported on the nearest hour. There also appears to be a peak at 12:00 which is likely a data quality issue in that reports may default to that time when not specified exactly. Otherwise this graph shows that crimes seems to peak at night around 6pm. But is this related to individual crimes and in/around parks?

```{r}
ggplot(df_filter, aes(x = Incident_HourTime, y=Premise_Derived )) +
  geom_density_ridges() +
  scale_x_continuous(limits = c(0,24), breaks = seq(0, 24, by = 1)) +
  facet_grid((VIC_Individual_Flag) ~ .) +
  labs(
      title = "Crimes by Premise and Time",
      subtitle = "Y = Indivuals, N = Entities/Businesses/NY State",
      x = "Time of Day (24 Clock)",
      y = "Premise Category"
      )
#TODO Show counts for each of these groups since not representative (ex what is a crime against and entity in a park)? Refer back to moaisic plot
```
From prior charts, we know that the number of crimes is skewed toward those occurring in "Inside". This does not represent the magnitude but we can see that for individuals, parks are more 'dangerous' at night - more so than other locations. However, it is somewhat comforting to know that this starts to drop off quickly after about 7-8pm. 


```{r}
#--Let's specifically look at crime around Columbia for Individuals

#ts_filter <- df_filter %>% filter(VIC_Individual_Flag == 'Y') %>% 
#  filter(dist_to_CU <= 2000) %>% #only 10k rows
#  filter(Premise_Derived == "PARK") #only 73 rows, not helpful

#--Box plot by time of day? TBD
```







## Location Analysis

1. Spatial distribution of all crime around Columbia University

Motivation: Since a component of our research is to analyze how crime is spread out around Columbia University, a visual analysis of spatial distribution of all crime around Columbia is useful. Following is a map centered around columbia university that shows where crime is distributed around Columbia University. 

```{r}
# Plottting columbia data on a map
library(ggmap)
columbia <- df_filter[df_filter$dist_to_CU <= 2000,]

register_google(key = "AIzaSyDUVtOF3qSoJEcQAZ9mU0E1rGKQDqcuNGw")
map = get_googlemap(center = c(lon = -73.963036, lat = 40.807384),zoom = 15)
ggmap(map) + geom_point(aes(x = Longitude, y = Latitude), data = columbia, , color = 'red', position=position_jitter(h=0.0001, w=0.0001), alpha = 0.05, size = 1) + 
  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank()) + ggtitle("Spatial distribution of crime around Columbia University")
```
Interpretation: 

- The above map is useful to see how geographical location of a crime is coded in the dataset - for example, all crimes happening on a particular street (or residences on a particular street) between two avenues is assigned to the lat-long coordinates of the center of that street (See W 111th St to W 124th St for instance). 

- Another thing the above map shows is around which subway station there is more crime. For example, out of the 2 125th st stations, the one on the right has noticeably more crime concentrated around it than the one on the left. Note that the way data is recorded, all crimes that happen inside a subway station are coded to the location of the subway station. So this result could also mean that one station is safer than the other. 

- This map could also be used to plan one's route to and from Columbia depending if safety is a concern. For example, one could see which streets and avenues have less crime concentrated on them and so could indicate which routes are generally safer to travel on.


```{r}
# Map of different crime types around Columbia

map = get_googlemap(center = c(lon = -73.963036, lat = 40.807384),zoom = 15)
ggmap(map) + geom_point(aes(x = Longitude, y = Latitude), data = columbia, , color = 'red', position=position_jitter(h=0.0001, w=0.0001), alpha = 0.05, size = 1) + 
  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank()) + facet_wrap(~CRIME_CAT)
```

2. Histogram of crime frequency with respect to increasing radius from Columbia

Motivation: Following histogram was produced to check how the crime frequency increases with increasing radius.

```{r}
# Line graph of density at different points

ggplot(columbia, aes(dist_to_CU)) +
  ggtitle("Histogram of crime counts wrt to distance from columbia") +
  geom_histogram(color = "blue", fill = "lightBlue", binwidth = 100)
```

Interpretation: This graph shows that within each 100m radius (up to 2000m away from Columbia), the crime frequency increases. The explanation is that because the increase in area considered within each 100m bin increases polynomially (with the power of 2), it's only natural that we see more crimes in buckets farther away from Columbia than those closer to columbia because the area considered within each bucket increases more than linearly. It is still interesting to note however that for some buckets the crime frequency goes down even though the area considered goes up. The next plots further investigate this issue using the concept of density of crime. 

3. Cumulative crime counts with respect to distance from Columbia University

Motivation: The previous plot motivated us to try to confirm whether the crime frequency follows a quadratic relationship with respect to radius from Columbia University. Note that this would imply that crime scales linearly with the area considered. 

```{r}
# Line graph of density at different points away from Columbia
library(tidyverse)
#columbia[, Radius := cut(dist_to_CU, breaks = c(0, 101, 201, 301, 401, 501, 601, 701, 801, 901, 1001, 1101, 1201, 1301, 1401, 1501, 1601, 1701, 1801, 1901, 2001), labels = c("0-100", "100-200", "3001-400", "10001-20000"))]

ggplot(columbia, aes(dist_to_CU)) +
  ggtitle("Histogram of cumulative crime counts wrt to distance from columbia") + stat_ecdf(color = "blue", fill = "lightBlue", binwidth = 100)


```

Interpretaion: Note that the curve roughly follows the shape of the quadratic curve confirming that the crime does increase linearly with area and quadratically with the radius considered. So then, what explains the decline in crime frequency observed in some of the buckets in the previous histogram? (For instance, the bucket that shows the crime frequency to drop between 1100m and 1200m as compared to the bucket that shows the crime frequency within 1000m and 1100m). We further explore this issue in our next plots. 

4. Cumulative and incremental density of crime with respect to distance from Columbia
Motivation: Since in the earlier histogram we saw that within some buckets the crime count was decreasing, we wanted to see how the density of crime changes as move away from Columbia generally and also specifically as we move from a bucket of 100m radius to the next bucket of the incremental 100m radius.

```{r}
# Making dataset to help plot density graphs

#Your code
factordist <- factor(cut(columbia$dist_to_CU, breaks=c(0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100)))
#Tabulate and turn into data.frame
xout <- as.data.frame(table(factordist))
#Add cumFreq and proportions
xout <- transform(xout, cumFreq = cumsum(Freq))
xout$factordist <- as.numeric(xout$factordist)

density <- xout %>% 
  mutate(dist = case_when(factordist==1 ~ 100,
                          factordist==2 ~ 200,
                          factordist==3 ~ 300,
                          factordist==4 ~ 400,
                          factordist==5 ~ 500,
                          factordist==6 ~ 600,
                          factordist==7 ~ 700,
                          factordist==8 ~ 800,
                          factordist==9 ~ 900,
                          factordist==10 ~ 1000,
                          factordist==11 ~ 1100,
                          factordist==12 ~ 1200,
                          factordist==13 ~ 1300,
                          factordist==14 ~ 1400,
                          factordist==15 ~ 1500,
                          factordist==16 ~ 1600,
                          factordist==17 ~ 1700,
                          factordist==18 ~ 1800,
                          factordist==19 ~ 1900,
                          factordist==20 ~ 2000))

density$cum_density <- density$cumFreq/(density$dist * density$dist)
density <- density %>%  mutate(incremental_area = dist*dist - lag(dist*dist, default = first(dist*dist)))
density$incremental_area[density$incremental_area == 0] <- 100*100

density$inc_density <- density$Freq/(density$incremental_area)

```

```{r}
# Making density graphs
cum_density_plt <- ggplot(density, aes(dist, cum_density)) + geom_line() + ggtitle("Cumulative density of crime with respect to distance from Columbia")

inc_density_plt <- ggplot(density, aes(dist, inc_density)) + geom_line() + ggtitle("Incremental density of crime with respect to distance from Columbia")

cum_density_plt
inc_density_plt
```

Interpretation: 

- Note that the cumulative density plot shows that crime is less dense within 750m of Columbia after which it becomes more dense. Potential explanations are that there could be extra policing around the campus area, or an increase in crime density due to an increase in population density as we move beyond 750m from Columbia. 

- The incremental density plot shows the increase (or decrease) in density as we move from a bucket of 100m to radius to the bucket of next 100m radius around Columbia. Note that this graph also shows what the earlier histogram showed, i.e., for some buckets the density of crime goes down. 



```{r}
# The following function uses the approximation that each degree of latitude represents 40075 / 360 kilometers and that each degree of longitude represents (40075 / 360) * cos(latitude) kilomemters. 

circles_data <- function(centers, radius, nPoints = 100){
    # centers: the data frame that has the lat/long coordinate of our point of interest
    # radius: radius measured in kilometer
    # nPoints: Defines the number of points on the circumference of the circle. The more the number of points, the smoother your circle will be
    meanLat <- mean(centers$latitude)
    # length per longitude changes with lattitude, so need correction
    radiusLon <- radius /111 / cos(meanLat/57.3) 
    radiusLat <- radius / 111
    circleDF <- data.frame(ID = rep(centers$ID, each = nPoints))
    angle <- seq(0,2*pi,length.out = nPoints)
    circleDF$lon <- unlist(lapply(centers$longitude, function(x) x + radiusLon * cos(angle)))
    circleDF$lat <- unlist(lapply(centers$latitude, function(x) x + radiusLat * sin(angle)))
    return(circleDF)
}


circle_100m <- circles_data(lat_long_data, 0.1)
circle_200m <- circles_data(lat_long_data, 0.2)
circle_300m <- circles_data(lat_long_data, 0.3)
circle_400m <- circles_data(lat_long_data, 0.4)
circle_500m <- circles_data(lat_long_data, 0.5)
circle_600m <- circles_data(lat_long_data, 0.6)
circle_700m <- circles_data(lat_long_data, 0.7)
circle_800m <- circles_data(lat_long_data, 0.8)
circle_900m <- circles_data(lat_long_data, 0.9)
circle_1000m <- circles_data(lat_long_data, 1)
```


5. Visualizing incremental density of crime within 1000m of Columbia

Motivation: To finally see why we see buckets of incremental 100m radius away from Columbia with decreasing density of crime, we decided to plot these buckets visually on a google map of the area around Columbia overlapped with the spatial density of crime. 

```{r}
map = get_googlemap(center = c(lon = -73.963036, lat = 40.807384),zoom = 15)

ggmap(map) + geom_point(aes(x = Longitude, y = Latitude), data = df_filter, , color = 'red', position=position_jitter(h=0.0001, w=0.0001), alpha = 0.1, size = 1) + geom_polygon(data = circle_100m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_200m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_300m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_400m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_500m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_600m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_700m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_800m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_900m, aes(lon, lat), color = "red", alpha = 0) +  geom_polygon(data = circle_1000m, aes(lon, lat), color = "red", alpha = 0) + theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank()) + ggtitle("Spatial distribution of crime wrt incremental radius of 100m away from Columbia")
```

Interpretation: We speculate that we see up and down jumps in incremental crime density due to the following reasons: 

1. While we increase the area in a circular fashion as we move away from Columbia, the lat/long coordinates of crime are recorded with the grid structure of Manhattan in mind. Therefore, some incremental radius/area buckets circles end up having way less crime reported if they contain parts of a park in them (since the crimes within parks are reported as happening on the streets outside the parks). 

2. Another reason is that many crimes are just reported to the center of the streets (as discussed in the spatial distribution map earlier). What ends up happening is that some incremental radius/area buckets end up including a straight line of all these concentrated crimes which lead to their crime density shooting up- see for example the area between the third last and the second last circle that ends up having majority of the crimes reported on streets W 112th to W 120th.

6. Counts of crime by borough

Motivation: When one decides to attend Columbia University, one may ask themselves which borough should they live in depending on the relative safety of living in each borough. Therefore, following are the plots of count of total crimes and different types of crimes by the boroughs.

```{r}
# Counts by Boroughs

df_filter <- df_filter %>% 
  mutate(Borough = case_when(
    BORO_NM %in% c("BRONX") ~ "BX",
    BORO_NM %in% c("BROOKLYN") ~ "BK",
    BORO_NM %in% c("MANHATTAN") ~ "MH",
    BORO_NM %in% c("QUEENS") ~ "QN",
    BORO_NM %in% c("STATEN ISLAND") ~ "SI"))

boroughs_cts <- ggplot(df_filter) +  geom_bar(aes(x=Borough)) + ggtitle("Overall crime counts by boroughs")

borough_cts_ctype <- ggplot(df_filter) +  geom_bar(aes(x=Borough)) + facet_wrap(~CRIME_CAT) + ggtitle("Counts of different types of crimes by boroughs")


boroughs_cts
borough_cts_ctype


```
Interpretation: 

1. Note that with respect to overall crime, Brooklyn has the most crime followed by Manhattan. 

2. It's interesting to note that while Brooklyn has more crime of typeS "SEX CRIMES", "MAJOR VIOLENT CRIMES", AND "FRAUD/GAMBLING AND MISC" compared to Manhattan while Manhattan has more crime of type "THEFT OR BURGLARY" and "DRUG AND ALCOHOL RELATED" compared to Brooklyn. 


